{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "!pip install -q transformers\n",
        "!pip install -q torchaudio\n",
        "!pip install -q moviepy\n",
        "!pip install -q pillow\n",
        "!pip install -q requests\n",
        "!pip install -q librosa\n",
        "!pip install -q soundfile\n",
        "!pip install -q accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKXFM6FVku3z",
        "outputId": "0e066ffa-b19b-4567-ac52-e42f3c138bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ak8-D70kkive",
        "outputId": "cda6f6c2-fc2b-419b-bff3-61b1facf439f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gradio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-abf4e067a1e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import gradio as gr\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from moviepy.editor import VideoFileClip\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline, WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "class DescripteurVideoAutomatique:\n",
        "    def __init__(self, intervalle=5, top_n=10, utiliser_cuda=True):\n",
        "        self.intervalle = intervalle\n",
        "        self.top_n = top_n\n",
        "        self.utiliser_cuda = utiliser_cuda\n",
        "        self.device = \"cuda\" if utiliser_cuda and torch.cuda.is_available() else \"cpu\"\n",
        "        self.chemin_video = None\n",
        "        self.scenes = []\n",
        "        self.descriptions = []\n",
        "        self.api_key_mistral = \"JpPD7Mcbkn4kt9EASK8FyXKT0s8zdNn5\"\n",
        "        self.bibliotheque_path = \"bibliotheque_videos.json\"\n",
        "        self.bibliotheque = self.charger_bibliotheque()\n",
        "\n",
        "    def charger_bibliotheque(self):\n",
        "        if os.path.exists(self.bibliotheque_path):\n",
        "            try:\n",
        "                with open(self.bibliotheque_path, 'r', encoding='utf-8') as f:\n",
        "                    return json.load(f)\n",
        "            except:\n",
        "                return []\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    def sauvegarder_bibliotheque(self):\n",
        "        with open(self.bibliotheque_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.bibliotheque, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    def generer_nom_descriptif(self, legendes, transcriptions):\n",
        "        \"\"\"GÃ©nÃ¨re un nom descriptif Ã  partir des lÃ©gendes et transcriptions\"\"\"\n",
        "        # Combinaison des 3 premiÃ¨res lÃ©gendes\n",
        "        nom_base = \" - \".join([leg.split(\".\")[0] for leg in legendes[:3] if leg])\n",
        "        # Limiter la longueur du nom\n",
        "        if not nom_base:\n",
        "            nom_base = \"VidÃ©o sans description\"\n",
        "        return nom_base[:50] + \"...\" if len(nom_base) > 50 else nom_base\n",
        "\n",
        "    def ajouter_a_bibliotheque(self, video_path, resultats, nom_personnalise=None):\n",
        "        nom_fichier = os.path.basename(video_path)\n",
        "        date_analyse = datetime.now().strftime(\"%d/%m/%Y %H:%M\")\n",
        "\n",
        "        # Extraction du premier moment intÃ©ressant\n",
        "        moment_interessant = \"Aucun moment intÃ©ressant trouvÃ©\"\n",
        "        if resultats:\n",
        "            top = max(resultats, key=lambda x: x[\"score\"])\n",
        "            moment_interessant = f\"{self.formater_temps(top['debut'])}-{self.formater_temps(top['fin'])}\"\n",
        "\n",
        "        # GÃ©nÃ©ration d'un nom descriptif si aucun nom personnalisÃ© n'est fourni\n",
        "        if not nom_personnalise:\n",
        "            legendes = [r[\"legende\"] for r in resultats[:3]] if resultats else []\n",
        "            transcriptions = [r[\"transcription\"] for r in resultats[:3]] if resultats else []\n",
        "            nom_descriptif = self.generer_nom_descriptif(legendes, transcriptions)\n",
        "        else:\n",
        "            nom_descriptif = nom_personnalise\n",
        "\n",
        "        # CrÃ©ation d'un identifiant unique basÃ© sur le nom et la date\n",
        "        video_id = f\"{nom_fichier}_{int(time.time())}\"\n",
        "\n",
        "        # Ajout Ã  la bibliothÃ¨que\n",
        "        self.bibliotheque.append({\n",
        "            \"id\": video_id,\n",
        "            \"nom\": nom_fichier,\n",
        "            \"nom_descriptif\": nom_descriptif,\n",
        "            \"chemin\": video_path,\n",
        "            \"date_analyse\": date_analyse,\n",
        "            \"moment_interessant\": moment_interessant,\n",
        "            \"nombre_scenes\": len(resultats) if resultats else 0\n",
        "        })\n",
        "\n",
        "        # Sauvegarde\n",
        "        self.sauvegarder_bibliotheque()\n",
        "\n",
        "        return self.bibliotheque\n",
        "\n",
        "    def charger_modele(self):\n",
        "        print(\"ğŸ“¦ Chargement des modÃ¨les...\")\n",
        "        # ModÃ¨le BLIP pour la description d'images\n",
        "        self.processeur = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "        self.modele = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(self.device)\n",
        "\n",
        "\n",
        "        # ModÃ¨le Whisper pour la transcription audio\n",
        "        self.whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "        self.whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(self.device)\n",
        "\n",
        "        # Traducteur\n",
        "        self.traducteur = pipeline(\"translation_en_to_fr\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "        print(\"âœ… ModÃ¨les chargÃ©s avec succÃ¨s!\")\n",
        "\n",
        "    def extraire_scenes(self):\n",
        "        clip = VideoFileClip(self.chemin_video)\n",
        "        duree = clip.duration\n",
        "        self.scenes = [(debut, min(debut + self.intervalle, duree)) for debut in range(0, int(duree), self.intervalle)]\n",
        "\n",
        "    def obtenir_image_milieu(self, debut, fin):\n",
        "        clip = VideoFileClip(self.chemin_video).subclip(debut, fin)\n",
        "        image = clip.get_frame((fin - debut) / 2)\n",
        "        return Image.fromarray(image)\n",
        "\n",
        "    def generer_legende(self, image):\n",
        "        inputs = self.processeur(image, return_tensors=\"pt\").to(self.device)\n",
        "        sortie = self.modele.generate(**inputs)\n",
        "        legende_en = self.processeur.decode(sortie[0], skip_special_tokens=True)\n",
        "        legende_fr = self.traducteur(legende_en)[0]['translation_text']\n",
        "        return legende_fr\n",
        "\n",
        "    def extraire_audio(self, debut, fin, nom=\"scene_audio.wav\"):\n",
        "        try:\n",
        "            clip = VideoFileClip(self.chemin_video).subclip(debut, fin)\n",
        "            if clip.audio is not None:\n",
        "                audio_path = os.path.join(os.getcwd(), nom)\n",
        "                clip.audio.write_audiofile(audio_path, logger=None)\n",
        "                return audio_path\n",
        "            else:\n",
        "                print(f\"Avertissement: Pas d'audio dans la section {debut}-{fin}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur d'extraction audio: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def transcrire_audio_whisper(self, audio_path):\n",
        "        if audio_path is None:\n",
        "            return \"Pas d'audio disponible pour cette section.\"\n",
        "\n",
        "        try:\n",
        "            import librosa\n",
        "            import soundfile as sf\n",
        "\n",
        "            # Chargement de l'audio\n",
        "            audio, rate = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            # Convertir en format attendu par Whisper\n",
        "            input_features = self.whisper_processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_features.to(self.device)\n",
        "\n",
        "            # GÃ©nÃ©rer les tokens de prÃ©diction\n",
        "            predicted_ids = self.whisper_model.generate(input_features, language=\"fr\", task=\"transcribe\")\n",
        "\n",
        "            # DÃ©codage de la transcription\n",
        "            transcription = self.whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "            if not transcription:\n",
        "                return \"Aucune transcription dÃ©tectÃ©e.\"\n",
        "\n",
        "            return transcription\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Erreur de transcription Whisper: {str(e)}\"\n",
        "        finally:\n",
        "            # Nettoyage du fichier\n",
        "            try:\n",
        "                if os.path.exists(audio_path):\n",
        "                    os.remove(audio_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    def demander_a_mistral(self, prompt, contexte=\"\"):\n",
        "        url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key_mistral}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"Vous Ãªtes un assistant spÃ©cialisÃ© dans l'analyse vidÃ©o. RÃ©pondez en franÃ§ais.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Contexte sur la vidÃ©o: {contexte}\\n\\nQuestion: {prompt}\"}\n",
        "        ]\n",
        "\n",
        "        data = {\n",
        "            \"model\": \"mistral-large-latest\",\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": 0.7,\n",
        "            \"max_tokens\": 800\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=data)\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "            return result[\"choices\"][0][\"message\"][\"content\"]\n",
        "        except Exception as e:\n",
        "            return f\"Erreur lors de la communication avec Mistral: {str(e)}\"\n",
        "\n",
        "    def decrire_video(self):\n",
        "        self.extraire_scenes()\n",
        "        self.descriptions = []\n",
        "\n",
        "        for debut, fin in self.scenes:\n",
        "            print(f\"Analyse de la scÃ¨ne {self.formater_temps(debut)}-{self.formater_temps(fin)}...\")\n",
        "\n",
        "            # GÃ©nÃ©ration de la lÃ©gende visuelle\n",
        "            image = self.obtenir_image_milieu(debut, fin)\n",
        "            legende = self.generer_legende(image)\n",
        "\n",
        "            # Extraction et transcription audio avec Whisper\n",
        "            audio_path = self.extraire_audio(debut, fin, nom=f\"audio_{int(debut)}.wav\")\n",
        "            transcription = self.transcrire_audio_whisper(audio_path)\n",
        "\n",
        "            # Calcul du score (pondÃ©ration ajustÃ©e pour favoriser les scÃ¨nes avec audio)\n",
        "            score = len(legende) * 0.05 + len(transcription) * 0.15 + np.random.rand() * 0.3\n",
        "\n",
        "            self.descriptions.append({\n",
        "                \"debut\": debut,\n",
        "                \"fin\": fin,\n",
        "                \"legende\": legende,\n",
        "                \"transcription\": transcription,\n",
        "                \"score\": score\n",
        "            })\n",
        "\n",
        "    def obtenir_meilleures_scenes(self):\n",
        "        return sorted(self.descriptions, key=lambda x: x[\"score\"], reverse=True)[:self.top_n]\n",
        "\n",
        "    def formater_temps(self, secondes):\n",
        "        return f\"{int(secondes // 60):02d}:{int(secondes % 60):02d}\"\n",
        "\n",
        "    def trouver_moment_interessant(self, scenes):\n",
        "        if not scenes:\n",
        "            return \"Aucun moment intÃ©ressant trouvÃ©\"\n",
        "\n",
        "        top = max(scenes, key=lambda x: x[\"score\"])\n",
        "        return f\"Le moment le plus intÃ©ressant se trouve entre {self.formater_temps(top['debut'])} et {self.formater_temps(top['fin'])}\"\n",
        "\n",
        "    def analyser_video(self, video_path, nom_personnalise=None):\n",
        "        if not video_path:\n",
        "            return None, \"Veuillez tÃ©lÃ©charger une vidÃ©o.\", None\n",
        "\n",
        "        # Sauvegarde du chemin de la vidÃ©o\n",
        "        self.chemin_video = video_path\n",
        "\n",
        "        # Chargement du modÃ¨le si nÃ©cessaire\n",
        "        if not hasattr(self, 'modele') or not hasattr(self, 'whisper_model'):\n",
        "            self.charger_modele()\n",
        "\n",
        "        # Analyse de la vidÃ©o\n",
        "        try:\n",
        "            self.decrire_video()\n",
        "            meilleures_scenes = self.obtenir_meilleures_scenes()\n",
        "            moment_interessant = self.trouver_moment_interessant(meilleures_scenes)\n",
        "\n",
        "            # CrÃ©ation d'un DataFrame pour l'affichage\n",
        "            df = pd.DataFrame([{\n",
        "                \"Rang\": i+1,\n",
        "                \"DÃ©but\": self.formater_temps(s[\"debut\"]),\n",
        "                \"Fin\": self.formater_temps(s[\"fin\"]),\n",
        "                \"Description\": s[\"legende\"],\n",
        "                \"Transcription audio\": s[\"transcription\"]\n",
        "            } for i, s in enumerate(meilleures_scenes)])\n",
        "\n",
        "            # Obtenir le nom de fichier de la vidÃ©o pour l'affichage\n",
        "            nom_fichier = os.path.basename(video_path)\n",
        "\n",
        "            # Ajout Ã  la bibliothÃ¨que\n",
        "            bibliotheque_mise_a_jour = self.ajouter_a_bibliotheque(video_path, self.descriptions, nom_personnalise)\n",
        "\n",
        "            return df, f\"VidÃ©o: {nom_fichier}\\n{moment_interessant}\", bibliotheque_mise_a_jour\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, f\"Erreur lors de l'analyse: {str(e)}\", None\n",
        "\n",
        "    def analyser_et_demander(self, video_path, prompt, nom_personnalise=None):\n",
        "        df, message, bibliotheque = self.analyser_video(video_path, nom_personnalise)\n",
        "\n",
        "        if df is None:\n",
        "            return None, message, None, bibliotheque\n",
        "\n",
        "        # PrÃ©paration du contexte pour Mistral\n",
        "        contexte = \"Informations sur les scÃ¨nes principales: \"\n",
        "        for i, row in df.head(3).iterrows():\n",
        "            contexte += f\"\\nScÃ¨ne {row['DÃ©but']}-{row['Fin']}: {row['Description']}. Audio: {row['Transcription audio']}\"\n",
        "\n",
        "        # Interrogation de Mistral\n",
        "        reponse_mistral = self.demander_a_mistral(prompt, contexte)\n",
        "\n",
        "        return df, message, reponse_mistral, bibliotheque\n",
        "\n",
        "# Interface Gradio\n",
        "def creer_interface():\n",
        "    # CrÃ©ation d'un descripteur partagÃ©\n",
        "    descr = DescripteurVideoAutomatique()\n",
        "\n",
        "    # Fonctions pour la manipulation de la bibliothÃ¨que\n",
        "    def charger_bibliotheque():\n",
        "        return pd.DataFrame([\n",
        "            {\"Index\": i, \"ID\": item[\"id\"], \"Nom\": item[\"nom\"],\n",
        "             \"Nom descriptif\": item.get(\"nom_descriptif\", \"\"),\n",
        "             \"Date d'analyse\": item[\"date_analyse\"],\n",
        "             \"Moment intÃ©ressant\": item[\"moment_interessant\"],\n",
        "             \"Nombre de scÃ¨nes\": item[\"nombre_scenes\"]}\n",
        "            for i, item in enumerate(descr.charger_bibliotheque())\n",
        "        ])\n",
        "\n",
        "    def supprimer_de_bibliotheque(index):\n",
        "        try:\n",
        "            index = int(index)\n",
        "            if 0 <= index < len(descr.bibliotheque):\n",
        "                descr.bibliotheque.pop(index)\n",
        "                descr.sauvegarder_bibliotheque()\n",
        "            return charger_bibliotheque()\n",
        "        except:\n",
        "            return charger_bibliotheque()\n",
        "\n",
        "    def ajouter_video_a_bibliotheque(video, nom_descriptif):\n",
        "        if not video:\n",
        "            return \"Veuillez tÃ©lÃ©charger une vidÃ©o.\", charger_bibliotheque()\n",
        "\n",
        "        try:\n",
        "            # Analyse simplifiÃ©e (juste pour l'extraction des scÃ¨nes)\n",
        "            descr.chemin_video = video\n",
        "            # S'assurer que les modÃ¨les sont chargÃ©s\n",
        "            if not hasattr(descr, 'modele') or not hasattr(descr, 'whisper_model'):\n",
        "                descr.charger_modele()\n",
        "\n",
        "            descr.extraire_scenes()\n",
        "            # Analyse de quelques scÃ¨nes clÃ©s seulement pour un traitement plus rapide\n",
        "            scenes_echantillon = descr.scenes[:3]\n",
        "            descriptions = []\n",
        "\n",
        "            for debut, fin in scenes_echantillon:\n",
        "                image = descr.obtenir_image_milieu(debut, fin)\n",
        "                legende = descr.generer_legende(image)\n",
        "                descriptions.append({\n",
        "                    \"debut\": debut,\n",
        "                    \"fin\": fin,\n",
        "                    \"legende\": legende,\n",
        "                    \"transcription\": \"\",\n",
        "                    \"score\": len(legende) * 0.05 + np.random.rand() * 0.3\n",
        "                })\n",
        "\n",
        "            # Ajout Ã  la bibliothÃ¨que avec le nom personnalisÃ©\n",
        "            descr.ajouter_a_bibliotheque(video, descriptions, nom_descriptif or None)\n",
        "            return f\"VidÃ©o ajoutÃ©e avec succÃ¨s: {os.path.basename(video)}\", charger_bibliotheque()\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Erreur lors de l'ajout: {str(e)}\", charger_bibliotheque()\n",
        "\n",
        "    # Fonction d'analyse pour une vidÃ©o avec prompt\n",
        "    def analyser_avec_prompt(video, prompt, nom_personnalise):\n",
        "        if not video:\n",
        "            return None, \"Veuillez tÃ©lÃ©charger une vidÃ©o.\", \"\", None\n",
        "        return descr.analyser_et_demander(video, prompt, nom_personnalise)\n",
        "\n",
        "    # Style CSS personnalisÃ© pour la barre de progrÃ¨s type Canva\n",
        "    css_personnalise = \"\"\"\n",
        "    .video-player {\n",
        "        max-width: 640px;\n",
        "        max-height: 360px;\n",
        "        margin: 0 auto;\n",
        "    }\n",
        "\n",
        "    .progress-bar-container {\n",
        "        width: 100%;\n",
        "        height: 10px;\n",
        "        background-color: #ddd;\n",
        "        border-radius: 5px;\n",
        "        overflow: hidden;\n",
        "        margin-top: -15px;\n",
        "        position: relative;\n",
        "        z-index: 10;\n",
        "    }\n",
        "\n",
        "    .progress-bar {\n",
        "        height: 100%;\n",
        "        background-color: #ff5722;\n",
        "        width: 0%;\n",
        "        transition: width 0.3s;\n",
        "    }\n",
        "\n",
        "    .time-display {\n",
        "        font-size: 14px;\n",
        "        margin-top: 5px;\n",
        "        text-align: center;\n",
        "    }\n",
        "\n",
        "    .video-card {\n",
        "        border: 1px solid #ddd;\n",
        "        border-radius: 10px;\n",
        "        padding: 10px;\n",
        "        margin-bottom: 15px;\n",
        "        background-color: #f9f9f9;\n",
        "    }\n",
        "\n",
        "    .bibliotheque-item {\n",
        "        padding: 10px;\n",
        "        border-bottom: 1px solid #eee;\n",
        "        border-radius: 5px;\n",
        "        margin-bottom: 5px;\n",
        "    }\n",
        "\n",
        "    .bibliotheque-item:hover {\n",
        "        background-color: #f0f0f0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # CrÃ©ation de l'interface principale\n",
        "    with gr.Blocks(css=css_personnalise, title=\"Descripteur Automatique de VidÃ©o\") as interface:\n",
        "        gr.Markdown(\"# Descripteur Automatique de VidÃ©o avec Whisper & Mistral AI\")\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Onglet Analyse de VidÃ©o\n",
        "            with gr.TabItem(\"Analyse de VidÃ©o\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=2):\n",
        "                        video_input = gr.Video(label=\"TÃ©lÃ©chargez votre vidÃ©o\", elem_classes=[\"video-player\"])\n",
        "                        nom_descriptif_analyse = gr.Textbox(label=\"Nom descriptif de la vidÃ©o (optionnel)\", placeholder=\"Laissez vide pour gÃ©nÃ©ration automatique\")\n",
        "                        gr.HTML(\"\"\"\n",
        "                        <div class=\"progress-bar-container\">\n",
        "                            <div class=\"progress-bar\" id=\"video-progress\"></div>\n",
        "                        </div>\n",
        "                        <div class=\"time-display\" id=\"time-display\">00:00 / 00:00</div>\n",
        "                        <script>\n",
        "                            document.addEventListener('DOMContentLoaded', function() {\n",
        "                                setTimeout(function() {\n",
        "                                    const videoElements = document.querySelectorAll('video');\n",
        "                                    videoElements.forEach(function(video) {\n",
        "                                        const progressBar = document.getElementById('video-progress');\n",
        "                                        const timeDisplay = document.getElementById('time-display');\n",
        "\n",
        "                                        video.addEventListener('timeupdate', function() {\n",
        "                                            const progress = (video.currentTime / video.duration) * 100;\n",
        "                                            progressBar.style.width = progress + '%';\n",
        "\n",
        "                                            const currentMinutes = Math.floor(video.currentTime / 60);\n",
        "                                            const currentSeconds = Math.floor(video.currentTime % 60);\n",
        "                                            const totalMinutes = Math.floor(video.duration / 60);\n",
        "                                            const totalSeconds = Math.floor(video.duration % 60);\n",
        "\n",
        "                                            timeDisplay.textContent =\n",
        "                                                `${currentMinutes.toString().padStart(2, '0')}:${currentSeconds.toString().padStart(2, '0')} /\n",
        "                                                ${totalMinutes.toString().padStart(2, '0')}:${totalSeconds.toString().padStart(2, '0')}`;\n",
        "                                        });\n",
        "                                    });\n",
        "                                }, 1000);\n",
        "                            });\n",
        "                        </script>\n",
        "                        \"\"\")\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        prompt_input = gr.Textbox(label=\"Posez une question sur cette vidÃ©o\", placeholder=\"Ex: Quels sont les points clÃ©s de cette vidÃ©o?\", lines=3)\n",
        "                        analyser_btn = gr.Button(\"Analyser la vidÃ©o\", variant=\"primary\")\n",
        "                        gr.Markdown(\"### RÃ©ponse de Mistral AI\")\n",
        "                        reponse_mistral = gr.Textbox(label=\"\", placeholder=\"La rÃ©ponse apparaÃ®tra ici aprÃ¨s l'analyse...\", lines=6)\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### Moments clÃ©s\")\n",
        "                        resultats_df = gr.DataFrame(label=\"\", headers=[\"Rang\", \"DÃ©but\", \"Fin\", \"Description\", \"Transcription audio\"])\n",
        "                        moment_interessant = gr.Textbox(label=\"Moment le plus intÃ©ressant\")\n",
        "\n",
        "                # Traitement du clic sur le bouton d'analyse\n",
        "                analyser_btn.click(\n",
        "                    fn=analyser_avec_prompt,\n",
        "                    inputs=[video_input, prompt_input, nom_descriptif_analyse],\n",
        "                    outputs=[resultats_df, moment_interessant, reponse_mistral, gr.State()]\n",
        "                )\n",
        "\n",
        "            # Onglet BibliothÃ¨que de VidÃ©os\n",
        "            with gr.TabItem(\"BibliothÃ¨que de VidÃ©os\"):\n",
        "                gr.Markdown(\"## Vos vidÃ©os analysÃ©es\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    bibliotheque_btn = gr.Button(\"Actualiser la bibliothÃ¨que\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    bibliotheque_list = gr.DataFrame(\n",
        "                        headers=[\"Index\", \"ID\", \"Nom\", \"Nom descriptif\", \"Date d'analyse\", \"Moment intÃ©ressant\", \"Nombre de scÃ¨nes\"],\n",
        "                        label=\"VidÃ©os sauvegardÃ©es\"\n",
        "                    )\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        index_suppression = gr.Number(label=\"Index de la vidÃ©o Ã  supprimer\", precision=0)\n",
        "                        supprimer_btn = gr.Button(\"Supprimer de la bibliothÃ¨que\")\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        gr.Markdown(\"### Ajouter une vidÃ©o Ã  la bibliothÃ¨que\")\n",
        "                        video_ajout = gr.Video(label=\"VidÃ©o Ã  ajouter\")\n",
        "                        nom_descriptif = gr.Textbox(label=\"Nom descriptif\", placeholder=\"Entrez un nom descriptif pour cette vidÃ©o\")\n",
        "                        ajouter_btn = gr.Button(\"Ajouter Ã  la bibliothÃ¨que\", variant=\"primary\")\n",
        "                        resultat_ajout = gr.Textbox(label=\"RÃ©sultat de l'ajout\")\n",
        "\n",
        "                # Chargement initial de la bibliothÃ¨que\n",
        "                interface.load(\n",
        "                    fn=charger_bibliotheque,\n",
        "                    inputs=None,\n",
        "                    outputs=bibliotheque_list\n",
        "                )\n",
        "\n",
        "                # Actualisation de la bibliothÃ¨que\n",
        "                bibliotheque_btn.click(\n",
        "                    fn=charger_bibliotheque,\n",
        "                    inputs=None,\n",
        "                    outputs=bibliotheque_list\n",
        "                )\n",
        "\n",
        "                # Suppression d'une vidÃ©o de la bibliothÃ¨que\n",
        "                supprimer_btn.click(\n",
        "                    fn=supprimer_de_bibliotheque,\n",
        "                    inputs=index_suppression,\n",
        "                    outputs=bibliotheque_list\n",
        "                )\n",
        "\n",
        "                # Ajout d'une vidÃ©o Ã  la bibliothÃ¨que\n",
        "                ajouter_btn.click(\n",
        "                    fn=ajouter_video_a_bibliotheque,\n",
        "                    inputs=[video_ajout, nom_descriptif],\n",
        "                    outputs=[resultat_ajout, bibliotheque_list]\n",
        "                )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Pour une utilisation dans Google Colab\n",
        "if __name__ == \"__main__\":\n",
        "    # Installation des dÃ©pendances si nÃ©cessaire\n",
        "    try:\n",
        "        import gradio\n",
        "    except ImportError:\n",
        "        print(\"ğŸ”§ Installation des dÃ©pendances nÃ©cessaires...\")\n",
        "        !pip install gradio transformers moviepy pillow requests librosa soundfile -q\n",
        "\n",
        "    try:\n",
        "        from transformers import WhisperProcessor\n",
        "    except:\n",
        "        !pip install transformers[torch] -q\n",
        "\n",
        "    # Importation des bibliothÃ¨ques aprÃ¨s installation\n",
        "    import gradio as gr\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline\n",
        "    from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "    from moviepy.editor import VideoFileClip\n",
        "\n",
        "    # Lancement de l'interface\n",
        "    interface = creer_interface()\n",
        "    interface.launch(debug=True, share=True)"
      ]
    }
  ]
}